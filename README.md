# Обучение модели Ирисов Фишера на основе деревьев принятия решений <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="MIT-License image"></a>

## 1. Описание проекта
**Проект по дисциплине:** МДК 13.01 Основы применения методов искусственного интеллекта в программировании.

**Практическое занятие №8:** Обучение моделей на основе деревьев принятия решений. Объединение множества деревьев с помощью случайных лесов.

В рамках работы была исследована задача классификации набора данных Iris с использованием моделей деревьев принятия решений и случайного леса. Произведено обучение моделей, оценка их производительности и анализ важности признаков. Использовались библиотеки *Pandas* для обработки данных, *Scikit-learn* для обучения моделей машинного обучения, *Matplotlib* и *Seaborn* для визуализации данных и результатов.

**Цель работы:** изучение и применение на практике методов машинного обучения на основе деревьев решений, а также сравнение их эффективности с другими подходами.


## 2. Скриншоты выполненного задания и конспекта лекции

### 2.1. Скриншоты выполненного задания

#### 2.1.1. Основной скрипт [main.py](src/main.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/11393e1d-edec-4987-a1d4-bda5e692a1dd" alt="main.py">
</p>

#### 2.1.2. Скрипт загрузки данных [data_loader.py](src/utils/data_loader.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/6bf443d6-8f48-48b3-a74f-eb3208c5216e" alt="data_loader.py">
</p>

#### 2.1.3. Скрипт визуализации данных [data_visualizer.py](src/visualization/data_visualizer.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/6a1220ba-2ae7-4c57-a64b-f0f58bfac5b8" alt="data_visualizer.py">
</p>

#### 2.1.4. Модель дерева принятия решений [decision_tree.py](src/models/decision_tree.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/e721b12a-ed81-4908-bdd1-39c82f9b788e" alt="src/models/decision_tree.py">
</p>

#### 2.1.5. Модель K-Nearest Neighbors (KNN) [knn.py](src/models/knn.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/80eebd54-9fea-47c5-904c-a182a1a63d07" alt="src/models/knn.py">
</p>

#### 2.1.6. Модель случайного леса [random_forest.py](src/models/random_forest.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/9a7f5b17-8854-495a-8aca-568e07bd5624" alt="src/models/random_forest.py">
</p>

### 2.2. Конспект лекции
<p align="center">
  <img src="report\lecture-notes\lecture-notes-1.jpg" alt="lecture-notes-1.jpg">
  <img src="report\lecture-notes\lecture-notes-2.jpg" alt="lecture-notes-2.jpg">
</p>

## 3. Методика и подходы

### 3.1. Методы

* **Загрузка данных:** Использован метод load_iris из библиотеки Scikit-learn для загрузки набора данных Iris.
* **Разделение данных:** Данные разделены на обучающую и тестовую выборки с использованием функции train_test_split.
* **Обучение модели дерева решений:** Модель DecisionTreeClassifier обучена на обучающей выборке.
* **Обучение модели случайного леса:** Модель RandomForestClassifier обучена на обучающей выборке с использованием различных гиперпараметров.
* **Оценка результатов:** Произведена оценка производительности моделей с использованием метрик accuracy, precision и recall.
* **Визуализация:** Данные и результаты визуализированы с использованием библиотек Matplotlib и Seaborn.

### 3.2. Алгоритмы
* **Дерево принятия решений:** Алгоритм построения дерева решений с использованием критериев Gini и entropy.
* **Случайный лес:** Алгоритм построения ансамбля деревьев решений с использованием случайного выбора признаков и данных.

### 3.3. Подходы

**Принципы KISS и DRY:**  Предприняты попытки следовать принципам KISS и DRY для упрощения и переиспользования кода.

### 3.4. Допущения и ограничения

* Набор данных Iris считается достаточно простым, и результаты могут не отражать производительность моделей на более сложных данных.
* Гиперпараметры моделей не оптимизировались с использованием сложных методов (например, grid search).

### 3.5. Инструменты, библиотеки и технологии

* Python
* Pandas
* Scikit-learn
* Matplotlib
* Seaborn

## 4. Результаты

### 4.1. Краткое описание данных

* **Источник данных:** `load_iris` из библиотеки Scikit-learn.
* **Формат данных:** Набор данных, представленный в виде массива NumPy.
* **Описание набора данных:** Набор данных Iris содержит измерения четырех признаков (длина и ширина чашелистика и лепестка) для трех видов ирисов (setosa, versicolor и virginica).

### 4.2. Предварительная обработка данных

* Разделение данных на признаки (X) и целевую переменную (y).
* Разделение данных на обучающую и тестовую выборки с использованием `train_test_split`.
* Масштабирование признаков (StandardScaler или MinMaxScaler) (указать, если использовалось).

### 4.3. Графики и диаграммы

#### 4.3.1. Дерево решений
<p align="center">
  <img src="report\graphics\decision_tree.dot.png" alt="decision-tree">
</p>

#### 4.3.2. График важности признаков
<p align="center">
  <img src="report\graphics\feature_importance.png" alt="feature-importance">
</p>

## 5. Анализ результатов

### 5.1. Результаты обучения дерева решений

Метрики на тестовой выборке:
* Accuracy: `1.0`
* Precision: `1.0`
* Recall: `1.0`
* F1: `1.0`

Результаты кросс-валидации:
* Accuracy: `0.9333333333333333`
* Precision: `0.9386243386243386`
* Recall: `0.9333333333333333`
* F1: `0.9330770769846399`

![image](https://github.com/user-attachments/assets/bf81dfda-68e1-4230-9580-f93ba8c803bc)

### 5.2. Результаты обучения случайного леса

Метрики на тестовой выборке:
* Accuracy: `1.0`
* Precision: `1.0`
* Recall: `1.0`
* F1: `1.0`

Результаты кросс-валидации:
* Accuracy: `0.9428571428571428`
* Precision: `0.9493386243386244`
* Recall: `0.9428571428571428`
* F1: `0.9425520464596093`

![image](https://github.com/user-attachments/assets/1be280ac-5b9a-4f7d-8dd3-8090f6853cec)

### 5.3. Результаты обучения KNN

Метрики на тестовой выборке:
* Accuracy: `1.0`
* Precision: `1.0`
* Recall: `1.0`
* F1: `1.0`

Результаты кросс-валидации:
* Accuracy: `0.9428571428571428`
* Precision: `0.9531481481481482`
* Recall: `0.9428571428571428`
* F1: `0.942022945930509`

![image](https://github.com/user-attachments/assets/20b2c170-12b7-467c-a097-8563f8cb78a5)

## 6. Выводы
Все три модели (Decision Tree, Random Forest и KNN) показали высокую эффективность на тестовой выборке, достигнув идеальных значений метрик accuracy, precision, recall и F1-score. Это свидетельствует о хорошей способности моделей к классификации на данном наборе данных.

Результаты кросс-валидации выявили небольшие различия между моделями. Модели Random Forest и KNN продемонстрировали незначительно более высокую обобщающую способность по сравнению с одиночным деревом решений, что может указывать на их лучшую устойчивость к переобучению на данном наборе данных. KNN показал себя немного точнее и полнее.

<p align="center">
  <img src="report\graphics\model_comparison_cv.png" alt="model-comparison-cv">
</p>

В целом, все три модели оказались эффективными для решения задачи классификации ирисов, однако модели Random Forest и KNN продемонстрировали небольшое преимущество в обобщающей способности, что делает их потенциально более надежными для использования на новых, ранее не виденных данных.

## 7. Обсуждение возможных улучшений

* Для улучшения результатов можно попробовать использовать другие модели машинного обучения, оптимизировать гиперпараметры моделей с использованием grid search.
* Провести более детальный анализ данных для выявления дополнительных признаков.

## 8. Заключение

В ходе выполнения данной работы были изучены и применены на практике методы машинного обучения на основе деревьев решений и случайных лесов. Получены навыки работы с библиотеками Pandas, Scikit-learn, Matplotlib и Seaborn. Проведено сравнение эффективности различных моделей и анализ важности признаков.

## 9. Лицензия

Этот проект распространяется под лицензией MIT - смотрите файл [LICENSE](LICENSE) для деталей.

## 10. Автор

Бедин Владислав ([MindlessMuse666](https://github.com/MindlessMuse666))

* GitHub: [MindlessMuse666](https://github.com/MindlessMuse666 "Владислав: https://github.com/MindlessMuse666")
* Telegram: [@mindless_muse](t.me/mindless_muse)
* Gmail: [mindlessmuse.666@gmail.com](mindlessmuse.666@gmail.com)
